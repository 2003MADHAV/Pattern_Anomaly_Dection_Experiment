{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ozZcu9P3H0D8ijc7jwax_OaBwPst0R6A","timestamp":1710698288661}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"whMP5owBiXHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qcEhYCsEicAT","executionInfo":{"status":"ok","timestamp":1710697905282,"user_tz":-330,"elapsed":42040,"user":{"displayName":"MADHAV KUMAR 2021-CSE BATCH","userId":"09910938514947058271"}},"outputId":"fea20e49-2796-4a60-bb00-5d63911062da","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDgPS6x1e-nB","outputId":"f5286083-0b46-429c-85a6-9ca559671f8c","executionInfo":{"status":"ok","timestamp":1710698270842,"user_tz":-330,"elapsed":14172,"user":{"displayName":"MADHAV KUMAR 2021-CSE BATCH","userId":"09910938514947058271"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Emotion: calm\n"]}],"source":["import os\n","import librosa\n","import soundfile\n","import numpy as np\n","import joblib\n","\n","\n","# Function to extract features from a sound file\n","def extract_feature(file_name, mfcc, chroma, mel):\n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype=\"float32\")\n","        sample_rate = sound_file.samplerate\n","        if chroma:\n","            stft = np.abs(librosa.stft(X))\n","        result = np.array([])\n","        if mfcc:\n","            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result = np.hstack((result, mfccs))\n","        if chroma:\n","            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n","            result = np.hstack((result, chroma))\n","        if mel:\n","            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n","            result = np.hstack((result, mel))\n","    return result\n","\n","# Load the pre-trained model using its file path\n","model_path = '/content/drive/MyDrive/PAD experiments-6,8,9,10/pad exp-6 datasets/speech-emotion.sav'\n","loaded_model = joblib.load(model_path)\n","\n","# Function to make predictions using the pre-trained model\n","def predict_emotion(file_path):\n","    feature = extract_feature(file_path, mfcc=True, chroma=True, mel=True)\n","    feature = feature.reshape(1, -1)\n","    prediction = loaded_model.predict(feature)\n","    return prediction[0]\n","\n","# Example usage\n","file_path = \"/content/drive/MyDrive/PAD experiments-6,8,9,10/pad exp-6 datasets/03-01-02-02-01-02-03.wav\"\n","predicted_emotion = predict_emotion(file_path)\n","print(\"Predicted Emotion:\", predicted_emotion)"]}]}